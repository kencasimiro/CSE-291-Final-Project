{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350c701d-47c8-4a74-87e3-2c144fa7ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Loading the data \n",
    "df = pd.read_csv(\"bank-additional-full.csv\", sep=';')\n",
    "df['label'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Protected attribute (binary) - married\n",
    "df['z'] = df['marital'].apply(lambda x: True if x.strip().lower() == 'married' else False)\n",
    "\n",
    "# Train/test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "# Helpers\n",
    "def row_to_tuple(row):\n",
    "    feat_dict = {\n",
    "        'age': row['age'],\n",
    "        'campaign': row['campaign'],\n",
    "        'pdays': row['pdays'],\n",
    "        'previous': row['previous'],\n",
    "    }\n",
    "    return (feat_dict, row['z'], row['label'])\n",
    "\n",
    "train_data = [row_to_tuple(r) for _, r in train_df.iterrows()]\n",
    "test_data  = [row_to_tuple(r) for _, r in test_df.iterrows()]\n",
    "\n",
    "# Test set - Separating features and the protected attribute\n",
    "dTest  = [d for (d, z, lbl) in test_data]\n",
    "zTest  = [z for (d, z, lbl) in test_data]\n",
    "y_true = [lbl for (d, z, lbl) in test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c55f1ab8-c5c9-48cc-ac53-271b35dad2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Helper TPR \n",
    "def tpr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute True Positive Rate = TP / (TP + FN).\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tp / float(tp + fn) if (tp + fn) else 0.0\n",
    "\n",
    "# Baseline\n",
    "def p1model():\n",
    "    \"\"\"\n",
    "    Baseline model with some tuned hyperparameters.\n",
    "    \"\"\"\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=300, \n",
    "        max_depth=10, \n",
    "        min_samples_leaf=20, \n",
    "        class_weight=\"balanced\", \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "def p1feat(d, z):\n",
    "    \"\"\"\n",
    "    Feature extraction for the baseline approach.\n",
    "    We'll include numeric fields from the bank dataset \n",
    "    plus the protected attribute if we want the model \n",
    "    to see it directly.\n",
    "    \"\"\"\n",
    "    numeric_keys = [\n",
    "        'age',\n",
    "        'campaign',\n",
    "        'pdays',\n",
    "        'previous',\n",
    "        'emp.var.rate',\n",
    "        'cons.price.idx',\n",
    "        'cons.conf.idx',\n",
    "        'euribor3m',\n",
    "        'nr.employed',\n",
    "    ]\n",
    "    numeric_features = [float(d.get(key, 0)) for key in numeric_keys]\n",
    "\n",
    "    # (Optional) incorporate protected attribute 'z' as a feature:\n",
    "    numeric_features.append(1.0 if z else 0.0)\n",
    "\n",
    "    return numeric_features\n",
    "\n",
    "\n",
    "# Dataset-Based Intervention \n",
    "def p2model():\n",
    "    \"\"\"\n",
    "    Model for dataset-based intervention. We can reuse the same \n",
    "    as baseline or adapt. Here, we just call p1model again.\n",
    "    \"\"\"\n",
    "    return p1model()\n",
    "\n",
    "def p2data(data, boost_factor=1.3):\n",
    "    \"\"\"\n",
    "    Rebalance the dataset with oversampling/undersampling \n",
    "    across groups to reduce disparity in the training data.\n",
    "    \n",
    "    data: list of (dict_of_features, z_bool, label_int)\n",
    "    boost_factor: controls how aggressively we oversample \n",
    "                  protected positives (for example).\n",
    "    \"\"\"\n",
    "    group_counts = {\n",
    "        True:  {0: [], 1: []},\n",
    "        False: {0: [], 1: []},\n",
    "    }\n",
    "    # Split data by (z, label)\n",
    "    for d, z, l in data:\n",
    "        group_counts[z][l].append((d, z, l))\n",
    "\n",
    "    # Identify the smaller negative group to match them\n",
    "    t_neg = min(len(group_counts[True][0]),  len(group_counts[False][0]))\n",
    "    # For positive, match the smaller group then apply boost_factor for the protected group\n",
    "    base_pos = min(len(group_counts[True][1]), len(group_counts[False][1]))\n",
    "\n",
    "    for z_val in [True, False]:\n",
    "        # positives\n",
    "        current_pos = len(group_counts[z_val][1])\n",
    "        if z_val is True:\n",
    "            target_pos = int(base_pos * boost_factor)\n",
    "        else:\n",
    "            target_pos = base_pos\n",
    "\n",
    "        if current_pos < target_pos:\n",
    "            group_counts[z_val][1] = resample(\n",
    "                group_counts[z_val][1],\n",
    "                replace=True,\n",
    "                n_samples=target_pos,\n",
    "                random_state=42\n",
    "            )\n",
    "        elif current_pos > target_pos:\n",
    "            group_counts[z_val][1] = resample(\n",
    "                group_counts[z_val][1],\n",
    "                replace=False,\n",
    "                n_samples=target_pos,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        # negatives\n",
    "        current_neg = len(group_counts[z_val][0])\n",
    "        if current_neg < t_neg:\n",
    "            group_counts[z_val][0] = resample(\n",
    "                group_counts[z_val][0],\n",
    "                replace=True,\n",
    "                n_samples=t_neg,\n",
    "                random_state=42\n",
    "            )\n",
    "        elif current_neg > t_neg:\n",
    "            group_counts[z_val][0] = resample(\n",
    "                group_counts[z_val][0],\n",
    "                replace=False,\n",
    "                n_samples=t_neg,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "    # Combine re-sampled sets\n",
    "    balanced_data = (group_counts[True][0] + group_counts[False][0] +\n",
    "                     group_counts[True][1] + group_counts[False][1])\n",
    "    return balanced_data\n",
    "\n",
    "# Model-Based (In-Processing) Intervention\n",
    "def p3feat(d):\n",
    "    \"\"\"\n",
    "    Similar to p1feat, but let's omit the protected attribute for in-processing \n",
    "    (we'll rely on sample weighting instead).\n",
    "    \"\"\"\n",
    "    numeric_keys = [\n",
    "        'age',\n",
    "        'campaign',\n",
    "        'pdays',\n",
    "        'previous',\n",
    "        'emp.var.rate',\n",
    "        'cons.price.idx',\n",
    "        'cons.conf.idx',\n",
    "        'euribor3m',\n",
    "        'nr.employed',\n",
    "    ]\n",
    "    numeric_features = [float(d.get(key, 0)) for key in numeric_keys]\n",
    "    return numeric_features\n",
    "\n",
    "def p3model(data):\n",
    "    \"\"\"\n",
    "    Assign group-aware sample weights to push the model to reduce \n",
    "    disparity in TPR across subgroups.\n",
    "    \"\"\"\n",
    "    # Count distribution\n",
    "    group_counts = {\n",
    "        (False, 0): 0,\n",
    "        (False, 1): 0,\n",
    "        (True, 0): 0,\n",
    "        (True, 1): 0\n",
    "    }\n",
    "    for (d, z, y) in data:\n",
    "        group_counts[(z, y)] += 1\n",
    "\n",
    "    total = len(data)\n",
    "    group_probs = {g: float(ct) / total for g, ct in group_counts.items()}\n",
    "\n",
    "    # Weighting hyperparameters\n",
    "    base_alpha = 1.2\n",
    "    alpha_adjustments = {\n",
    "        (True, 1): 1.5,   # heavier weight for protected positives\n",
    "        (True, 0): 1.3,   # maybe some weight for protected negatives too\n",
    "        # You can add more adjustments if needed\n",
    "    }\n",
    "\n",
    "    X, y_labels, sample_weights = [], [], []\n",
    "\n",
    "    for (d, z, label) in data:\n",
    "        X.append(p3feat(d))\n",
    "        y_labels.append(label)\n",
    "\n",
    "        alpha = alpha_adjustments.get((z, label), base_alpha)\n",
    "        w = 1.0 / (group_probs[(z, label)] ** alpha)\n",
    "\n",
    "        # Just a clamp to avoid extremely large weights\n",
    "        w = min(w, 100.0)\n",
    "        w = max(w, 1.0)\n",
    "\n",
    "        sample_weights.append(w)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=10,\n",
    "        min_samples_leaf=20,\n",
    "        class_weight=None,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X, y_labels, sample_weight=sample_weights)\n",
    "    return model\n",
    "\n",
    "# Post-Processing Intervention\n",
    "def p4labels(test_scores, zTest):\n",
    "    \"\"\"\n",
    "    Adjust decision thresholds by group after seeing the raw model scores.\n",
    "\n",
    "    test_scores: e.g., predicted probabilities from .predict_proba\n",
    "    zTest: list of booleans for protected attribute\n",
    "    \"\"\"\n",
    "    test_scores = np.array(test_scores)\n",
    "    zTest = np.array(zTest)\n",
    "\n",
    "    # Partition scores by group\n",
    "    scores_group0 = test_scores[zTest == False]\n",
    "    scores_group1 = test_scores[zTest == True]\n",
    "\n",
    "    # For example, pick the 50th percentile for each group\n",
    "    thr0 = np.percentile(scores_group0, 50)\n",
    "    thr1 = np.percentile(scores_group1, 50)\n",
    "\n",
    "    # Some small shift if you want to tip the thresholds\n",
    "    # thr0 -= 0.01\n",
    "    # thr1 += 0.01\n",
    "\n",
    "    final_preds = []\n",
    "    for s, z in zip(test_scores, zTest):\n",
    "        if not z:\n",
    "            final_preds.append(1 if s > thr0 else 0)\n",
    "        else:\n",
    "            final_preds.append(1 if s > thr1 else 0)\n",
    "\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0df2d7-388d-457f-8db7-66e043757b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the CSV\n",
    "df = pd.read_csv(\"bank-additional-full.csv\", sep=';')\n",
    "\n",
    "# 2. Create binary label: y => 1 if \"yes\", else 0\n",
    "df['label'] = df['y'].map({'yes':1, 'no':0})\n",
    "\n",
    "# 3. Choose a protected attribute. For example, True if \"married\", else False\n",
    "df['z'] = df['marital'].apply(lambda x: True if x.strip().lower() == 'married' else False)\n",
    "\n",
    "# 4. Train/Test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "    # 5. Convert each row to (feature_dict, z_bool, label)\n",
    "def row_to_tuple(row):\n",
    "    return ({\n",
    "                'age':            row['age'],\n",
    "                'campaign':       row['campaign'],\n",
    "                'pdays':          row['pdays'],\n",
    "                'previous':       row['previous'],\n",
    "                'emp.var.rate':   row['emp.var.rate'],\n",
    "                'cons.price.idx': row['cons.price.idx'],\n",
    "                'cons.conf.idx':  row['cons.conf.idx'],\n",
    "                'euribor3m':      row['euribor3m'],\n",
    "                'nr.employed':    row['nr.employed']\n",
    "            },\n",
    "            row['z'],\n",
    "            row['label'])\n",
    "\n",
    "train_data = [row_to_tuple(r) for _, r in train_df.iterrows()]\n",
    "test_data  = [row_to_tuple(r) for _, r in test_df.iterrows()]\n",
    "\n",
    "# For convenience, define X_test, y_test, z_test arrays\n",
    "X_test_p1 = [p1feat(d, z) for (d, z, _) in test_data]\n",
    "y_test    = [lbl for (_, _, lbl) in test_data]\n",
    "z_test    = [z for (_, z, _) in test_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23c748e-2dca-4525-a113-db5023e9b0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline ===\n",
      "Accuracy: 0.851\n",
      "TPR (Protected):   0.629\n",
      "TPR (Unprotected): 0.678\n",
      "TPR difference:    0.049\n"
     ]
    }
   ],
   "source": [
    "    ################################\n",
    "    # BASELINE\n",
    "    ################################\n",
    "    clf_baseline = p1model()\n",
    "    X_train_p1   = [p1feat(d, z) for (d, z, _) in train_data]\n",
    "    y_train      = [lbl for (_, _, lbl) in train_data]\n",
    "    clf_baseline.fit(X_train_p1, y_train)\n",
    "    y_pred_base  = clf_baseline.predict(X_test_p1)\n",
    "\n",
    "    acc_base = accuracy_score(y_test, y_pred_base)\n",
    "    tpr_prot_base = tpr([y_test[i] for i, z in enumerate(z_test) if z],\n",
    "                        [y_pred_base[i] for i, z in enumerate(z_test) if z])\n",
    "    tpr_unprot_base = tpr([y_test[i] for i, z in enumerate(z_test) if not z],\n",
    "                          [y_pred_base[i] for i, z in enumerate(z_test) if not z])\n",
    "    diff_base = abs(tpr_prot_base - tpr_unprot_base)\n",
    "\n",
    "    print(\"\\n=== Baseline ===\")\n",
    "    print(f\"Accuracy: {acc_base:.3f}\")\n",
    "    print(f\"TPR (Protected):   {tpr_prot_base:.3f}\")\n",
    "    print(f\"TPR (Unprotected): {tpr_unprot_base:.3f}\")\n",
    "    print(f\"TPR difference:    {diff_base:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e42728-b73f-4678-9797-228b77430d95",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "Accuracy = 85.1%: \n",
    "This is a reasonably good predictive performance.\n",
    "TPR (Protected) = 0.629 vs. TPR (Unprotected) = 0.678.\n",
    "The difference of 0.049 (about 5%) suggests that the model is missing relatively more positives from the protected group (or said differently, the protected group’s true positive rate is about 5% lower than the unprotected group’s).\n",
    "\n",
    "This difference can be considered “unfairness” if our fairness goal is to have equal TPR (sometimes referred to as equal opportunity). The 5% gap is not huge, but it is still sizable enough that we might worry about systematic disparities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c031dfbe-b563-47fc-8b76-3cc7d2de24d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset-Based Intervention ===\n",
      "Accuracy: 0.854\n",
      "TPR (Protected):   0.648\n",
      "TPR (Unprotected): 0.642\n",
      "TPR difference:    0.007\n"
     ]
    }
   ],
   "source": [
    "    ################################\n",
    "    # DATASET-BASED INTERVENTION\n",
    "    ################################\n",
    "    balanced_data = p2data(train_data, boost_factor=1.3)\n",
    "    clf_p2 = p2model()\n",
    "    X_train_bal = [p1feat(d, z) for (d, z, _) in balanced_data]\n",
    "    y_train_bal = [lbl for (_, _, lbl) in balanced_data]\n",
    "    clf_p2.fit(X_train_bal, y_train_bal)\n",
    "    y_pred_p2  = clf_p2.predict(X_test_p1)\n",
    "\n",
    "    acc_p2 = accuracy_score(y_test, y_pred_p2)\n",
    "    tpr_prot_p2 = tpr([y_test[i] for i, z in enumerate(z_test) if z],\n",
    "                      [y_pred_p2[i] for i, z in enumerate(z_test) if z])\n",
    "    tpr_unprot_p2 = tpr([y_test[i] for i, z in enumerate(z_test) if not z],\n",
    "                        [y_pred_p2[i] for i, z in enumerate(z_test) if not z])\n",
    "    diff_p2 = abs(tpr_prot_p2 - tpr_unprot_p2)\n",
    "\n",
    "    print(\"\\n=== Dataset-Based Intervention ===\")\n",
    "    print(f\"Accuracy: {acc_p2:.3f}\")\n",
    "    print(f\"TPR (Protected):   {tpr_prot_p2:.3f}\")\n",
    "    print(f\"TPR (Unprotected): {tpr_unprot_p2:.3f}\")\n",
    "    print(f\"TPR difference:    {diff_p2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cafc81b-a271-42c4-aaea-f714cc06d944",
   "metadata": {},
   "source": [
    "## Dataset-Based Interventionm\n",
    "\n",
    "Accuracy = 85.4% (slightly higher than the baseline’s 85.1% in this case).\n",
    "TPR is now 0.648 vs. 0.642 for protected vs. unprotected, yielding a TPR difference of only 0.007—a significant drop from 0.049. So the gap is nearly gone.\n",
    "Curiously, the accuracy improved fractionally in this example. Often, rebalancing can either lower or maintain overall accuracy, but it may also shift the decision boundary in a way that helps classification if the original dataset was heavily skewed. The key is that the group TPRs are now quite close, so from a fairness standpoint, this approach was very effective at bringing TPR parity.\n",
    "\n",
    "### How much can ‘unfairness’ be explained by dataset characteristics, and can it be fixed with dataset-based interventions?\n",
    "\n",
    "Unfairness can often arise from imbalanced data—if certain groups (e.g., protected) have fewer positive examples or the label distribution is skewed, the model might learn weaker decision boundaries for that group. By oversampling or undersampling different subgroups (particularly boosting the protected group’s positive samples), we effectively supply the classifier with a more balanced dataset. In this case, the results show that adjusting the data distribution strongly affects the model’s TPR disparity. The original 5% gap shrank to under 1% (0.7 percentage points). This indicates that a large portion of the initial unfairness was indeed attributable to the underlying data imbalance rather than the model’s inherent bias alone. Because the dataset-based approach also maintained or slightly improved overall accuracy, it seems that pre-processing interventions can be a very practical first step to mitigating unfairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f10fd0a-b991-49dd-be5d-8b8124b5cf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model-Based (In-Processing) Intervention ===\n",
      "Accuracy: 0.531\n",
      "TPR (Protected):   0.836\n",
      "TPR (Unprotected): 0.877\n",
      "TPR difference:    0.041\n"
     ]
    }
   ],
   "source": [
    "    ################################\n",
    "    # MODEL-BASED (IN-PROCESSING) INTERVENTION\n",
    "    ################################\n",
    "    clf_p3 = p3model(train_data)\n",
    "    X_test_p3 = [p3feat(d) for (d, z, _) in test_data] \n",
    "    y_pred_p3  = clf_p3.predict(X_test_p3)\n",
    "\n",
    "    acc_p3 = accuracy_score(y_test, y_pred_p3)\n",
    "    tpr_prot_p3 = tpr([y_test[i] for i, z in enumerate(z_test) if z],\n",
    "                      [y_pred_p3[i] for i, z in enumerate(z_test) if z])\n",
    "    tpr_unprot_p3 = tpr([y_test[i] for i, z in enumerate(z_test) if not z],\n",
    "                        [y_pred_p3[i] for i, z in enumerate(z_test) if not z])\n",
    "    diff_p3 = abs(tpr_prot_p3 - tpr_unprot_p3)\n",
    "\n",
    "    print(\"\\n=== Model-Based (In-Processing) Intervention ===\")\n",
    "    print(f\"Accuracy: {acc_p3:.3f}\")\n",
    "    print(f\"TPR (Protected):   {tpr_prot_p3:.3f}\")\n",
    "    print(f\"TPR (Unprotected): {tpr_unprot_p3:.3f}\")\n",
    "    print(f\"TPR difference:    {diff_p3:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53123f06-7ebd-43d8-a850-ee5cfd08831e",
   "metadata": {},
   "source": [
    "# Model-Based (In-Processing) Intervention\n",
    "\n",
    "Accuracy = 53.1%, which is a steep drop from our 85%+ in the baseline and dataset-based methods.\n",
    "TPR: protected group has 0.836, unprotected has 0.877, so the difference is 0.041. That’s a bit lower than the baseline gap (0.049) but significantly higher than the dataset-based approach (0.007).\n",
    "The big story is the loss in accuracy: from ~85% down to ~53%. The model, via in-processing reweighting, is aggressively pushing for fewer missed positives (i.e., higher TPR) but apparently at a massive cost in overall classification performance.\n",
    "\n",
    "### How do different modeling choices impact fairness characteristics, and can we fix them with in-processing?\n",
    "\n",
    "An in-processing approach typically changes how the model is trained (e.g., custom loss functions or sample weighting) so that it gives more weight to certain subgroups or outcomes. This can push the model to treat protected and unprotected groups more similarly in terms of TPR. In theory, this approach can be very flexible and direct—rather than artificially rebalancing data, we reweight or otherwise penalize the model for uneven performance. However, it can also produce large side effects if not carefully tuned. Here, we see that while TPR difference is somewhat reduced (down from 0.049 to 0.041), we lost a lot of accuracy (down to 0.531). That drop suggests our chosen weighting or hyperparameters might be over-correcting. In real scenarios, we would likely experiment with different weighting strengths or advanced in-processing techniques to balance the accuracy–fairness trade-off better. Nonetheless, in-processing can indeed help reduce unfairness, but it may do so at a significant cost to other metrics if not carefully tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7e822c-8e88-4d08-9223-61b0836940b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Post-Processing Intervention ===\n",
      "Accuracy: 0.575\n",
      "TPR (Protected):   0.836\n",
      "TPR (Unprotected): 0.827\n",
      "TPR difference:    0.009\n"
     ]
    }
   ],
   "source": [
    "    ################################\n",
    "    # POST-PROCESSING INTERVENTION\n",
    "    ################################\n",
    "    # We'll reuse the baseline model's probabilities for demonstration, \n",
    "    # then apply group-specific thresholds.\n",
    "    test_scores = clf_baseline.predict_proba(X_test_p1)[:,1]\n",
    "    y_pred_p4 = p4labels(test_scores, z_test)\n",
    "\n",
    "    acc_p4 = accuracy_score(y_test, y_pred_p4)\n",
    "    tpr_prot_p4 = tpr([y_test[i] for i, z in enumerate(z_test) if z],\n",
    "                      [y_pred_p4[i] for i, z in enumerate(z_test) if z])\n",
    "    tpr_unprot_p4 = tpr([y_test[i] for i, z in enumerate(z_test) if not z],\n",
    "                        [y_pred_p4[i] for i, z in enumerate(z_test) if not z])\n",
    "    diff_p4 = abs(tpr_prot_p4 - tpr_unprot_p4)\n",
    "\n",
    "    print(\"\\n=== Post-Processing Intervention ===\")\n",
    "    print(f\"Accuracy: {acc_p4:.3f}\")\n",
    "    print(f\"TPR (Protected):   {tpr_prot_p4:.3f}\")\n",
    "    print(f\"TPR (Unprotected): {tpr_unprot_p4:.3f}\")\n",
    "    print(f\"TPR difference:    {diff_p4:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317cd9b-fcdd-49e3-843c-1becc54ad551",
   "metadata": {},
   "source": [
    "## Post-Processing Intervenction\n",
    "\n",
    "Accuracy = 57.5%, which is also a large reduction from ~85%.\n",
    "TPR (Protected): 0.836 vs. TPR (Unprotected): 0.827. So the gap is 0.009—which is small.\n",
    "This method yields TPR parity nearly on par with the dataset-based approach, but at a severe cost to accuracy.\n",
    "\n",
    "### Can you apply post-processing interventions to achieve desired fairness outcomes?\n",
    "Yes, post-processing is a relatively straightforward approach: after you train a model in the usual way, you can assign different decision thresholds for each group. Often you choose thresholds to match TPR or FPR across groups. This can drastically reduce the TPR disparity, which we see here dropping to 0.009 (less than 1% difference). However, you may pay a price in overall metrics like accuracy or precision. By changing the threshold for certain groups, you might be increasing false positives or false negatives in ways that reduce the overall classification performance. In our example, accuracy fell to 57.5%. This is a big drop from 85%. Whether that trade-off is acceptable depends on the domain. Sometimes, if your legal or ethical framework prioritizes TPR fairness, post-processing might be worthwhile despite the accuracy penalty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe54e6-d40b-498d-9534-d51ee3de715b",
   "metadata": {},
   "source": [
    "### What types of interventions are most appropriate for your task, and what are the trade-offs?\n",
    "Deciding on the “right” intervention involves domain context, legal requirements, and a cost–benefit analysis of how much accuracy you can sacrifice for fairness:\n",
    "\n",
    "1. Dataset-Based:\n",
    "Pros: Easy to implement, can significantly reduce TPR gaps if imbalance is the main cause. Sometimes leads to minimal accuracy losses—or even small gains—because rebalancing can help the model learn underrepresented patterns.\n",
    "\n",
    "Cons: Might produce artificial distributions that do not reflect the real world. If you oversample too heavily, the model may overfit. Also, if the original data truly reflects reality, forcibly balancing subgroups might not be seen as “accurate” representation.\n",
    "\n",
    "2. Model-Based (In-Processing):\n",
    "Pros: More fine-grained control over how fairness constraints are enforced. Potentially powerful for adjusting a variety of fairness definitions (e.g., TPR parity, predictive parity, etc.).\n",
    "\n",
    "Cons: Can be complicated to tune. We saw an extreme accuracy drop (to 53%) which suggests we might have set weighting hyperparameters too aggressively. This approach can be more code-intensive, requiring specialized algorithms or cost functions.\n",
    "\n",
    "3. Post-Processing:\n",
    "Pros: Conceptually simple; you do not have to retrain or alter the data. You can quickly experiment with group-specific thresholds.\n",
    "\n",
    "Cons: Usually yields a bigger trade-off on overall performance metrics (like accuracy, precision, or recall) because you are overriding the model’s “natural” decision boundaries. If you push TPR parity strongly, you often raise false positives (or false negatives) in certain subgroups, which can severely hurt accuracy or precision.\n",
    "\n",
    "\n",
    "### What is best?\n",
    "The baseline model started with a 5% TPR gap between protected and unprotected groups. A dataset-based intervention nearly eliminated that gap (down to 0.7%) while retaining strong accuracy (even slightly higher than baseline). An in-processing approach reduced the TPR gap somewhat (down to ~4%), but at a steep accuracy cost (53%). A post-processing approach nearly equalized TPR (gap ~1%) but also significantly hurt accuracy (58%). These results illustrate the trade-offs typical in fairness interventions: balancing group-level parity with overall performance. The best method will depend on legal requirements, domain needs, and how much accuracy can be sacrificed for improved fairness.\n",
    "\n",
    "The baseline model achieved 85.1% accuracy, with a TPR of 0.629 for the protected group and 0.678 for the unprotected group, yielding a TPR difference of 0.049. This initial gap suggests that the model is missing relatively more true positives in the protected group. Such a difference is often viewed as unfair if our goal is to ensure equal opportunity (i.e., similar TPRs) for all groups. Because our baseline was trained on the raw data, it is possible that the underlying dataset distributions contributed heavily to this disparity.\n",
    "\n",
    "When applying a dataset-based intervention through oversampling and undersampling, overall accuracy slightly improved to 85.4%, while the TPR gap nearly vanished (0.007). This outcome implies that much of the observed unfairness was caused by class and subgroup imbalances in the original dataset. By giving the classifier additional training samples for protected-group positives, the model was able to learn more balanced decision boundaries. The result is a near-equal TPR across protected and unprotected segments with no performance penalty—making this intervention both easy to implement and highly effective.\n",
    "\n",
    "In contrast, the in-processing approach, which reweighted samples in the training phase to emphasize protected-group performance, drove accuracy down to 53.1%. Although it somewhat reduced the TPR gap (from 0.049 to 0.041), the steep drop in accuracy rendered the model less reliable overall. Similarly, the post-processing strategy, wherein different thresholds were assigned to each group after the model produced probability scores, cut the TPR difference to 0.009 but sank accuracy to 57.5%. Post-processing can be appealing because it is simple to deploy after model training, but as seen here, it can significantly erode global performance metrics.\n",
    "\n",
    "Given these outcomes, the dataset-based intervention appears the most appropriate for this specific task: it preserves high accuracy while nearly eliminating the TPR gap. If legal regulations or organizational policies require strict fairness mandates, a post-processing approach might be layered on top as a fine-tuning measure. However, the large losses in accuracy suggest that in this dataset and modeling setup, both in-processing and post-processing strategies need further calibration to reduce unintended performance sacrifices. The best practice in real-world scenarios would be to thoroughly iterate and tune each method, while also weighing the ethical, legal, and business considerations relevant to the model’s domain of application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31602bad-8516-44a6-a3f2-ded49b83bb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "marital_counts = df['marital'].apply(lambda x: 'Married' if x.strip().lower() == 'married' else 'Not Married').value_counts()\n",
    "    \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.bar(marital_counts.index, marital_counts.values, color=['cornflowerblue', 'lightcoral'])\n",
    "plt.title(\"Distribution of Marital Status in Bank Marketing Dataset\")\n",
    "plt.xlabel(\"Marital Status\")\n",
    "plt.ylabel(\"Number of Clients\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab127a5-b786-4131-8557-ec7f20160e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
