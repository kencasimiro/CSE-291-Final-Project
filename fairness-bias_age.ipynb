{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca64366-3cb3-472c-9bb7-d3a1cd9f62c6",
   "metadata": {},
   "source": [
    "### Sensitive Attribute (z) is age.\n",
    "\n",
    "We chose age as our sensitive attribute because age is a legally protected characteristic and it often correlates with differing financial behaviors and needs. For example, younger individuals typically require more liquidity and are less likely to commit to long-term savings products like bank term deposits due to their dynamic financial circumstances and greater likelihood of needing immediate access to cash. On the other hand, older individuals often have more financial stability and may be more inclined to lock in funds for a higher return. This naturally creates a potential for unfairness where models trained on historical data might inadvertently favor older clients while neglecting younger ones—even if the underlying behavior differences are statistically true on average. By focusing on age, we can analyze and quantify these disparities (e.g., through differences in true positive rates) and then apply fairness interventions to ensure that the model does not systematically disadvantage younger clients, making our results both interesting and practically relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee26f4c-072f-406b-9751-25aa10e7e896",
   "metadata": {},
   "source": [
    "### Fairness Metric - TPR\n",
    "We chose the true positive rate (TPR) difference as our primary fairness metric because it directly measures the model's ability to correctly identify positive cases (i.e., clients who subscribe to a term deposit) across different groups. In our context, ensuring that the TPR is similar for both the protected group (e.g., older clients, age ≥ 40) and the unprotected group (younger clients, age < 40) is critical for guaranteeing equal opportunity. A low TPR difference indicates that clients with a genuine likelihood to subscribe are equally recognized by the model, regardless of their age. This metric is particularly relevant because misclassifying a true positive (especially for a group that might already be under-targeted) can lead to missed opportunities and potential discrimination. Using TPR difference allows us to quantify fairness in a way that aligns with both legal and ethical standards while directly addressing the core objective of our predictive task.\n",
    "\n",
    "Misclassifying a client who is likely to subscribe (a false negative) can mean denying a beneficial financial product to that individual, which is especially problematic if it happens disproportionately for one age group. By focusing on the TPR, we ensure that both older (protected) and younger (unprotected) clients who are truly eligible for the product are equally likely to be identified by the model. This is legally and ethically relevant, as it prevents systematic underrepresentation of any group. Our argument emphasizes that, given the potential consequences for customer access and fairness in financial services, using TPR difference as our fairness metric is not only justified but essential for the responsible deployment of the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733eec9c-0572-4b34-9ac1-c43a48c3fcdd",
   "metadata": {},
   "source": [
    "### Data Preparation + Base Model\n",
    "\n",
    "We import the necessary libraries (pandas, NumPy, scikit-learn, etc.) and define a helper function for calculating the True Positive Rate (TPR). We created a baseline model—a RandomForestClassifier with certain hyperparameters—and a feature extraction function (p1feat) that transforms each data row into a numeric feature vector. In this feature extraction, a boolean “z” is appended to the numeric features to mark whether a client is “older” (age ≥ 40) or not.\n",
    "\n",
    "Our code then loads the bank-additional-full.csv dataset and converts the “y” column to a binary label indicating whether a client subscribed to a term deposit, and then creates the sensitive attribute z based on age (True if age ≥ 40). The data is split into training and test sets, preserving label distribution via stratification. Finally, create tuples of (features, z, label) for each row in the training and test DataFrames. The test data is converted into arrays (X_test_p1, y_test, and z_test) using the p1feat function so that the model can later be trained and evaluated on how well it predicts subscriptions while tracking potential fairness concerns regarding age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b57aa0-dbd6-4404-b873-e04899e21082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#######################################\n",
    "# HELPER: True Positive Rate Function #\n",
    "#######################################\n",
    "def tpr(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tp / float(tp + fn) if (tp + fn) != 0 else 0.0\n",
    "\n",
    "def p1model():\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=300, \n",
    "        max_depth=10, \n",
    "        min_samples_leaf=20, \n",
    "        class_weight=\"balanced\", \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "def p1feat(d, z):\n",
    "    numeric_keys = [\n",
    "        'age', \n",
    "        'campaign', \n",
    "        'pdays', \n",
    "        'previous', \n",
    "        'emp.var.rate',\n",
    "        'cons.price.idx',\n",
    "        'cons.conf.idx',\n",
    "        'euribor3m',\n",
    "        'nr.employed'\n",
    "    ]\n",
    "    features = [float(d.get(key, 0)) for key in numeric_keys]\n",
    "    # Optionally include the sensitive attribute (age indicator) as a feature.\n",
    "    # Here, z is expected to be True if age >= 40, False otherwise.\n",
    "    features.append(1.0 if z else 0.0)\n",
    "    return features\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Main Execution: Loading Data and Running Models\n",
    "#########################################\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load dataset\n",
    "    df = pd.read_csv(\"bank-additional-full.csv\", sep=';')\n",
    "    \n",
    "    # 2. Create the binary target label from \"y\"\n",
    "    df['label'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "    \n",
    "    # 3. Define the sensitive attribute using age:\n",
    "    df['z'] = df['age'].apply(lambda x: True if x >= 40 else False)\n",
    "\n",
    "    # 4. Split data into train and test sets\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "    \n",
    "    # 5. Convert DataFrame rows into tuples: (feature_dict, sensitive attribute, label)\n",
    "    def row_to_tuple(row):\n",
    "        features = {\n",
    "            'age': row['age'],\n",
    "            'campaign': row['campaign'],\n",
    "            'pdays': row['pdays'],\n",
    "            'previous': row['previous'],\n",
    "            'emp.var.rate': row['emp.var.rate'],\n",
    "            'cons.price.idx': row['cons.price.idx'],\n",
    "            'cons.conf.idx': row['cons.conf.idx'],\n",
    "            'euribor3m': row['euribor3m'],\n",
    "            'nr.employed': row['nr.employed']\n",
    "        }\n",
    "        return (features, row['z'], row['label'])\n",
    "    \n",
    "    train_data = [row_to_tuple(r) for _, r in train_df.iterrows()]\n",
    "    test_data  = [row_to_tuple(r) for _, r in test_df.iterrows()]\n",
    "    \n",
    "    # Prepare test data arrays using baseline feature extraction (p1feat)\n",
    "    X_test_p1 = [p1feat(d, z) for (d, z, _) in test_data]\n",
    "    y_test = [lbl for (_, _, lbl) in test_data]\n",
    "    z_test = [z for (_, z, _) in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d2698-4071-4e72-a3ea-a5f13265963d",
   "metadata": {},
   "source": [
    "### Reasoning - Why we chose 'age'\n",
    "\n",
    "From the bar chart, we can see that the Younger category (clients under 40) is somewhat larger than the Older category (clients 40 or above). Specifically, there appear to be around 22,000 Younger clients versus roughly 19,000 Older clients in the dataset. Although the split isn’t extremely imbalanced, the difference is notable enough that a model trained on this data might learn age-dependent patterns—particularly if older individuals also tend to exhibit different term-deposit subscription behaviors. This distribution helps explain why age can serve as a meaningful sensitive attribute in fairness analyses: there is a sizable portion of clients in both age brackets, yet any model bias toward one group or the other could manifest in observable disparities, such as a gap in true positive rates or overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab77cbeb-1716-426b-8a54-3794e37d0ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['age_group'] = df['age'].apply(lambda x: 'Older' if x >= 40 else 'Younger')\n",
    "age_counts = df['age_group'].value_counts()\n",
    "    \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.bar(age_counts.index, age_counts.values, color=['skyblue', 'salmon'])\n",
    "plt.title(\"Distribution of Age Groups (Older: Age >= 40, Younger: Age < 40)\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Number of Clients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f9463-7884-4c5a-b7be-08833ed4f840",
   "metadata": {},
   "source": [
    "### Baseline Model - Code\n",
    "\n",
    "In this snippet, we first create a baseline Random Forest model (clf_baseline) and train it on the extracted features (X_train_p1) and labels (y_train) from the training data. The code then makes predictions (y_pred_baseline) on the test set (X_test_p1) and computes overall accuracy. Next, it calculates the True Positive Rate (TPR) separately for the protected group—clients aged 40 or older—and for the unprotected group—clients under 40. TPR measures how often the model correctly identifies actual positives (i.e., clients who truly subscribed) within each subgroup. Finally, it reports the absolute difference between these TPR values. \n",
    "\n",
    "### Baseline Model - Results\n",
    "\n",
    "The results show an accuracy of 0.853, indicating that the model correctly classifies about 85.3% of test samples. The protected group’s TPR is 0.661, while the unprotected group’s TPR is 0.634, producing a TPR gap of 0.027. In other words, older clients (age ≥ 40) are caught as “true positives” roughly 2.7 percentage points more often than younger clients, suggesting a modest age-related disparity in the baseline model’s predictions. \n",
    "\n",
    "In our baseline model, we observed an overall accuracy of 85.3%, with a True Positive Rate (TPR) of 66.1% for the older group (age ≥ 40) and 63.4% for the younger group (age < 40), resulting in a TPR gap of 2.7 percentage points. This gap indicates that our model is slightly more effective at correctly identifying positive cases (term deposit subscriptions) among older clients compared to younger ones. Some of this disparity can be explained by the inherent characteristics of the dataset—if older individuals indeed have a higher propensity to subscribe based on historical behavior, the dataset will naturally reflect that trend. However, even if the trend is real, age is a legally protected attribute, and any systematic difference in model performance that favors one age group over another can be viewed as unfair. In our case, the 2.7% gap suggests that while a part of the unfairness may stem from genuine differences in financial behavior between age groups, there remains an element of bias that could disadvantage younger clients. This justifies the need for further fairness interventions to ensure that the model’s predictions do not disproportionately favor one group solely due to their age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6239c660-e326-4c47-9263-19e2319b2e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Model ===\n",
      "Accuracy: 0.853\n",
      "TPR (Protected - Older, age>=40): 0.661\n",
      "TPR (Unprotected - Younger, age<40): 0.634\n",
      "TPR Difference: 0.027\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# Baseline Model Evaluation\n",
    "##############################\n",
    "clf_baseline = p1model()\n",
    "X_train_p1 = [p1feat(d, z) for (d, z, _) in train_data]\n",
    "y_train = [lbl for (_, _, lbl) in train_data]\n",
    "clf_baseline.fit(X_train_p1, y_train)\n",
    "y_pred_baseline = clf_baseline.predict(X_test_p1)\n",
    "\n",
    "acc_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "tpr_prot_base = tpr([y_test[i] for i, z in enumerate(z_test) if z],\n",
    "                    [y_pred_baseline[i] for i, z in enumerate(z_test) if z])\n",
    "tpr_unprot_base = tpr([y_test[i] for i, z in enumerate(z_test) if not z],\n",
    "                      [y_pred_baseline[i] for i, z in enumerate(z_test) if not z])\n",
    "diff_baseline = abs(tpr_prot_base - tpr_unprot_base)\n",
    "\n",
    "print(\"=== Baseline Model ===\")\n",
    "print(f\"Accuracy: {acc_baseline:.3f}\")\n",
    "print(f\"TPR (Protected - Older, age>=40): {tpr_prot_base:.3f}\")\n",
    "print(f\"TPR (Unprotected - Younger, age<40): {tpr_unprot_base:.3f}\")\n",
    "print(f\"TPR Difference: {diff_baseline:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125cb902-401e-4f99-af03-bccb3cb72164",
   "metadata": {},
   "source": [
    "### Dataset-Based Intervenction - Code\n",
    "\n",
    "This code implements a dataset-based intervention aimed at mitigating potential bias by rebalancing the training data across sensitive groups and outcomes. First, it organizes the data into four groups based on the sensitive attribute z (for example, age-based: True if age ≥ 40, False otherwise) and the binary label (0 or 1). It then determines the target count for each subgroup by taking the minimum counts among negatives and positives across the sensitive groups. For each group, if there are fewer positive or negative examples than the target, the code oversamples those examples using resampling with replacement; if there are too many, it undersamples them without replacement. Finally, the balanced subgroups are combined into one dataset that aims to equalize the distribution of labels across the sensitive attribute. The accompanying p2model() function simply returns the baseline Random Forest model, which will then be trained on this rebalanced data, potentially reducing any unfairness that may have been introduced by imbalanced training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37061801-5b27-4457-8276-46aa8fb3412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 2. Dataset-Based Intervention (p2)\n",
    "#########################################\n",
    "def p2data(data, boost_factor=1.3):\n",
    "    # Organize the data by sensitive attribute and label\n",
    "    group_counts = { True: {0: [], 1: []}, False: {0: [], 1: []} }\n",
    "    for d, z, lbl in data:\n",
    "        group_counts[z][lbl].append((d, z, lbl))\n",
    "    \n",
    "    # Identify target counts to balance negatives and positives\n",
    "    target_neg = min(len(group_counts[True][0]), len(group_counts[False][0]))\n",
    "    base_pos = min(len(group_counts[True][1]), len(group_counts[False][1]))\n",
    "    \n",
    "    # Resample positives and negatives for each group\n",
    "    for z_val in [True, False]:\n",
    "        current_pos = len(group_counts[z_val][1])\n",
    "        target_pos = int(base_pos * boost_factor) if z_val is True else base_pos\n",
    "        if current_pos < target_pos:\n",
    "            group_counts[z_val][1] = resample(\n",
    "                group_counts[z_val][1],\n",
    "                replace=True,\n",
    "                n_samples=target_pos,\n",
    "                random_state=42\n",
    "            )\n",
    "        elif current_pos > target_pos:\n",
    "            group_counts[z_val][1] = resample(\n",
    "                group_counts[z_val][1],\n",
    "                replace=False,\n",
    "                n_samples=target_pos,\n",
    "                random_state=42\n",
    "            )\n",
    "        current_neg = len(group_counts[z_val][0])\n",
    "        if current_neg < target_neg:\n",
    "            group_counts[z_val][0] = resample(\n",
    "                group_counts[z_val][0],\n",
    "                replace=True,\n",
    "                n_samples=target_neg,\n",
    "                random_state=42\n",
    "            )\n",
    "        elif current_neg > target_neg:\n",
    "            group_counts[z_val][0] = resample(\n",
    "                group_counts[z_val][0],\n",
    "                replace=False,\n",
    "                n_samples=target_neg,\n",
    "                random_state=42\n",
    "            )\n",
    "    \n",
    "    # Combine all groups\n",
    "    balanced_data = (group_counts[True][0] + group_counts[False][0] +\n",
    "                     group_counts[True][1] + group_counts[False][1])\n",
    "    return balanced_data\n",
    "\n",
    "def p2model():\n",
    "    # For dataset-based, we can use the same model as the baseline.\n",
    "    return p1model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2055a2d-cbd1-4704-bc09-082aa1acddf7",
   "metadata": {},
   "source": [
    "### Dataset-Based Intervention - Results\n",
    "#### Answers: How much can “unfairness” in your predictions be explained by dataset haracteristics? Can you fix them with dataset-based interventions?\n",
    "\n",
    "The dataset-based intervention was designed to rebalance the training data across the sensitive groups (in this case, based on age) so that the model would have a more equal representation of positive and negative outcomes from both older (protected, age ≥ 40) and younger (unprotected, age < 40) clients. In our results, we observe that the overall accuracy increased slightly to 85.8%. However, the intervention resulted in a True Positive Rate (TPR) of 66.8% for older clients and 61.5% for younger clients, leading to a TPR difference of 5.4 percentage points.\n",
    "\n",
    "While the idea behind dataset-based interventions is to reduce unfairness caused by imbalances in the training data, our results suggest that, in this instance, the intervention actually increased the gap between the groups. This could indicate that the rebalancing process overcorrected for the underrepresented outcomes or that the underlying dataset characteristics (such as the natural differences in subscription behavior between age groups) are too strong to be fully mitigated by a simple resampling strategy. In other words, although part of the unfairness might be explained by dataset characteristics, our current dataset-based intervention did not fix the unfairness—instead, it amplified the disparity in TPR between the older and younger groups. This result suggests that additional tuning or alternative fairness interventions (such as model-based or post-processing methods) might be needed to achieve a more balanced outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d57bc6b2-613d-42cb-b69a-3d8c840ad190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset-Based Intervention ===\n",
      "Accuracy: 0.858\n",
      "TPR (Protected): 0.668\n",
      "TPR (Unprotected): 0.615\n",
      "TPR Difference: 0.054\n"
     ]
    }
   ],
   "source": [
    "    ###########################################\n",
    "    # Dataset-Based Intervention Evaluation (p2)\n",
    "    ###########################################\n",
    "    balanced_data = p2data(train_data, boost_factor=1.3)\n",
    "    clf_p2 = p2model()\n",
    "    X_train_p2 = [p1feat(d, z) for (d, z, _) in balanced_data]\n",
    "    y_train_p2 = [lbl for (_, _, lbl) in balanced_data]\n",
    "    clf_p2.fit(X_train_p2, y_train_p2)\n",
    "    y_pred_p2 = clf_p2.predict(X_test_p1)\n",
    "    \n",
    "    acc_p2 = accuracy_score(y_test, y_pred_p2)\n",
    "    tpr_prot_p2 = tpr([y_test[i] for i, z in enumerate(z_test) if z],\n",
    "                      [y_pred_p2[i] for i, z in enumerate(z_test) if z])\n",
    "    tpr_unprot_p2 = tpr([y_test[i] for i, z in enumerate(z_test) if not z],\n",
    "                        [y_pred_p2[i] for i, z in enumerate(z_test) if not z])\n",
    "    diff_p2 = abs(tpr_prot_p2 - tpr_unprot_p2)\n",
    "    \n",
    "    print(\"\\n=== Dataset-Based Intervention ===\")\n",
    "    print(f\"Accuracy: {acc_p2:.3f}\")\n",
    "    print(f\"TPR (Protected): {tpr_prot_p2:.3f}\")\n",
    "    print(f\"TPR (Unprotected): {tpr_unprot_p2:.3f}\")\n",
    "    print(f\"TPR Difference: {diff_p2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846843c-86ac-4054-93f1-5e8305685377",
   "metadata": {},
   "source": [
    "### Model-Based (In-processing) Intervention - Code\n",
    "\n",
    "This code implements a model-based (in-processing) fairness intervention that adjusts the training process by assigning different weights to each sample based on its group frequency. The function p3feat(d) extracts a fixed set of numeric features from a dictionary representing a data sample (including fields like age, campaign, pdays, and so on), converting them into a list of floating-point numbers. In the p3model(data) function, the code first computes the frequency of each combination of sensitive attribute (here, age-based, with the sensitive attribute z being either True or False) and binary label (0 or 1). It then calculates the probability for each group by dividing the group count by the total number of samples. For each sample, the code assigns a weight that is the inverse of the corresponding group probability raised to a power (alpha), where a higher alpha value (taken from the alpha_adjustments dictionary for certain groups) increases the weight for underrepresented groups. These weights are clamped to lie between 1 and 100 to avoid extreme values. Finally, the function trains a Random Forest classifier using these computed sample weights, effectively forcing the model to pay more attention to samples from groups that are underrepresented or more likely to be misclassified. The resulting model is then returned, incorporating fairness considerations directly into its training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04fb9fef-fe9b-4b51-915e-0eb69fd7a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 3. Model-Based (In-Processing) Intervention (p3)\n",
    "#########################################\n",
    "def p3feat(d):\n",
    "    numeric_keys = [\n",
    "        'age', \n",
    "        'campaign', \n",
    "        'pdays', \n",
    "        'previous', \n",
    "        'emp.var.rate',\n",
    "        'cons.price.idx',\n",
    "        'cons.conf.idx',\n",
    "        'euribor3m',\n",
    "        'nr.employed'\n",
    "    ]\n",
    "    return [float(d.get(key, 0)) for key in numeric_keys]\n",
    "\n",
    "def p3model(data):\n",
    "    # Compute the distribution of (sensitive, label) combinations\n",
    "    group_counts = { (False, 0): 0, (False, 1): 0, (True, 0): 0, (True, 1): 0 }\n",
    "    for d, z, lbl in data:\n",
    "        group_counts[(z, lbl)] += 1\n",
    "    total = len(data)\n",
    "    group_probs = { g: float(count) / total for g, count in group_counts.items() }\n",
    "    \n",
    "    base_alpha = 1.2\n",
    "    alpha_adjustments = { (True, 1): 1.5, (True, 0): 1.3 }\n",
    "    \n",
    "    X, y_labels, sample_weights = [], [], []\n",
    "    for d, z, lbl in data:\n",
    "        X.append(p3feat(d))\n",
    "        y_labels.append(lbl)\n",
    "        alpha = alpha_adjustments.get((z, lbl), base_alpha)\n",
    "        w = 1.0 / (group_probs[(z, lbl)] ** alpha)\n",
    "        w = min(w, 100.0)\n",
    "        w = max(w, 1.0)\n",
    "        sample_weights.append(w)\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=300, \n",
    "        max_depth=10, \n",
    "        min_samples_leaf=20, \n",
    "        class_weight=None, \n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X, y_labels, sample_weight=sample_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a36685-f817-4c5a-9d88-8874b369e84e",
   "metadata": {},
   "source": [
    "### Model-Based (In-processing) Intervention - Results\n",
    "#### Answers: How do different modeling choices impact fairness characteristics? Can you fix them with in-processing interventions?\n",
    "\n",
    "In our model-based intervention, we adjusted the training process by assigning different sample weights based on the group frequency of each (sensitive, label) combination. The goal was to force the model to pay more attention to underrepresented groups in the training data, ideally reducing unfairness. However, the results show that while the protected group (clients aged 40 or older) achieved a very high TPR of 0.878, the unprotected group (clients under 40) only reached a TPR of 0.698—a gap of 18 percentage points. Additionally, overall accuracy dropped to 63.3%. This indicates that the in-processing intervention, as currently configured, has not fixed the unfairness; in fact, it appears to have exacerbated the disparity between the groups. The weighting strategy may be overcompensating for the protected group, leading to a model that over-predicts positives for older clients while under-predicting for younger ones. Thus, while different modeling choices such as sample reweighting can have a direct impact on fairness metrics, achieving a balanced performance requires careful tuning of the in-processing method to avoid a significant drop in overall accuracy and an increased TPR gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "143bec78-8519-4432-868b-a63e60200314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model-Based (In-Processing) Intervention ===\n",
      "Accuracy: 0.633\n",
      "TPR (Protected): 0.878\n",
      "TPR (Unprotected): 0.698\n",
      "TPR Difference: 0.180\n"
     ]
    }
   ],
   "source": [
    "    ###########################################\n",
    "    # Model-Based (In-Processing) Intervention Evaluation (p3)\n",
    "    ###########################################\n",
    "    clf_p3 = p3model(train_data)\n",
    "    X_test_p3 = [p3feat(d) for (d, z, _) in test_data]\n",
    "    y_pred_p3 = clf_p3.predict(X_test_p3)\n",
    "    \n",
    "    acc_p3 = accuracy_score(y_test, y_pred_p3)\n",
    "    tpr_prot_p3 = tpr([y_test[i] for i, z in enumerate(z_test) if z],\n",
    "                      [y_pred_p3[i] for i, z in enumerate(z_test) if z])\n",
    "    tpr_unprot_p3 = tpr([y_test[i] for i, z in enumerate(z_test) if not z],\n",
    "                        [y_pred_p3[i] for i, z in enumerate(z_test) if not z])\n",
    "    diff_p3 = abs(tpr_prot_p3 - tpr_unprot_p3)\n",
    "    \n",
    "    print(\"\\n=== Model-Based (In-Processing) Intervention ===\")\n",
    "    print(f\"Accuracy: {acc_p3:.3f}\")\n",
    "    print(f\"TPR (Protected): {tpr_prot_p3:.3f}\")\n",
    "    print(f\"TPR (Unprotected): {tpr_unprot_p3:.3f}\")\n",
    "    print(f\"TPR Difference: {diff_p3:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7167d29-8993-47ef-b915-2df8539dc860",
   "metadata": {},
   "source": [
    "### Post-Processing Intervention - Code\n",
    "This function below implements a post-processing intervention that adjusts the final binary predictions by applying different decision thresholds to each sensitive group. First, it converts the test scores and sensitive attribute array into NumPy arrays. Then, it partitions the test scores into two groups—one for samples where the sensitive attribute is False (for example, \"younger\") and another where it is True (for example, \"older\"). For each group, the function computes the 50th percentile (median) of the scores, which serves as a threshold. Finally, for each test sample, if its score exceeds the threshold corresponding to its group, it is assigned a positive prediction (1); otherwise, a negative prediction (0). This method aims to mitigate fairness issues by adjusting the decision boundary separately for each group, so that any imbalance in score distributions is addressed in the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f7624f-f35a-4747-85a7-419fde83297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 4. Post-Processing Intervention (p4)\n",
    "#########################################\n",
    "def p4labels(test_scores, zTest):\n",
    "    test_scores = np.array(test_scores)\n",
    "    zTest = np.array(zTest)\n",
    "    \n",
    "    # Partition scores by group\n",
    "    scores_group0 = test_scores[zTest == False]\n",
    "    scores_group1 = test_scores[zTest == True]\n",
    "    \n",
    "    # Define group-specific thresholds based on the 50th percentile\n",
    "    thr0 = np.percentile(scores_group0, 50)\n",
    "    thr1 = np.percentile(scores_group1, 50)\n",
    "    \n",
    "    preds = []\n",
    "    for s, z in zip(test_scores, zTest):\n",
    "        preds.append(1 if s > (thr1 if z else thr0) else 0)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91726776-9899-4aff-835d-0f4fd49ee44b",
   "metadata": {},
   "source": [
    "### Post-Processing Intervention - Results\n",
    "#### Can you apply post-processing interventions to achieve desired fairness outcomes?\n",
    "\n",
    "The post-processing intervention code works by adjusting the decision thresholds separately for each group based on the median of the model’s predicted scores. In our results, after applying this intervention, the overall accuracy dropped to 57.5%, but the True Positive Rates (TPRs) for the protected group (older clients) and unprotected group (younger clients) became 83.8% and 82.2%, respectively—a TPR difference of only 1.6 percentage points. This demonstrates that post-processing can be effective in achieving a more balanced outcome across groups by fine-tuning the threshold for each group independently. However, while this method nearly equalizes the TPRs and thus significantly improves fairness in that metric, it comes with the trade-off of a substantial overall accuracy loss compared to the baseline model. In summary, post-processing interventions can indeed be applied to achieve desired fairness outcomes, but careful consideration must be given to the resulting trade-offs between fairness and overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b3068a2-6452-49bc-b912-4ed3120ca4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Post-Processing Intervention ===\n",
      "Accuracy: 0.575\n",
      "TPR (Protected): 0.838\n",
      "TPR (Unprotected): 0.822\n",
      "TPR Difference: 0.016\n"
     ]
    }
   ],
   "source": [
    "    ###########################################\n",
    "    # Post-Processing Intervention Evaluation (p4)\n",
    "    ###########################################\n",
    "    test_scores = clf_baseline.predict_proba(X_test_p1)[:, 1]\n",
    "    y_pred_p4 = p4labels(test_scores, z_test)\n",
    "    \n",
    "    acc_p4 = accuracy_score(y_test, y_pred_p4)\n",
    "    tpr_prot_p4 = tpr([y_test[i] for i, z in enumerate(z_test) if z],\n",
    "                      [y_pred_p4[i] for i, z in enumerate(z_test) if z])\n",
    "    tpr_unprot_p4 = tpr([y_test[i] for i, z in enumerate(z_test) if not z],\n",
    "                        [y_pred_p4[i] for i, z in enumerate(z_test) if not z])\n",
    "    diff_p4 = abs(tpr_prot_p4 - tpr_unprot_p4)\n",
    "    \n",
    "    print(\"\\n=== Post-Processing Intervention ===\")\n",
    "    print(f\"Accuracy: {acc_p4:.3f}\")\n",
    "    print(f\"TPR (Protected): {tpr_prot_p4:.3f}\")\n",
    "    print(f\"TPR (Unprotected): {tpr_unprot_p4:.3f}\")\n",
    "    print(f\"TPR Difference: {diff_p4:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9359e30-4a19-4a14-a380-b3ecaba45744",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "#### Answers: What types of interventions are most appropriate for your task (e.g. legal, practical to deploy, etc.)? What are the tradeoffs between them (e.g. how are other metrics negatively impacted by a particular intervention, etc.)\n",
    "\n",
    "The choice of fairness intervention depends heavily on the context and priorities of the task—in our case, predicting whether a client will subscribe to a bank term deposit while ensuring equitable treatment across age groups. Our experiments show that different methods yield very different trade-offs. For instance, the dataset-based intervention, which involves resampling to rebalance the distribution of positives and negatives across age groups, resulted in an overall accuracy of 85.8% but produced a true positive rate (TPR) of 66.8% for the older group (age ≥ 40) versus 61.5% for the younger group (age < 40), with a TPR difference of 5.4 percentage points. While this method is generally practical and easy to deploy—since it only requires manipulating the training data—it did not fully mitigate unfairness in our case; in fact, the gap widened compared to the baseline. This suggests that dataset-based interventions can sometimes be limited by the inherent behavior patterns captured in the data.\n",
    "\n",
    "In contrast, our model-based (in-processing) intervention, which adjusts sample weights during training based on the frequency of (sensitive, label) combinations, resulted in a dramatic drop in overall accuracy to 63.3% and an even larger TPR disparity (18 percentage points). Although in-processing methods have the theoretical advantage of incorporating fairness constraints directly into the training algorithm, they require careful tuning; otherwise, they may overcompensate for one group at the expense of overall performance. This accuracy loss and amplified gap indicate that without precise calibration, in-processing interventions might negatively impact other performance metrics and are less practical for production systems that need high overall accuracy.\n",
    "\n",
    "On the other hand, the post-processing intervention, which applies group-specific thresholds after model prediction, managed to reduce the TPR gap to just 1.6 percentage points, with TPRs of 83.8% and 82.2% for the older and younger groups respectively. However, this came at the cost of a significant decrease in overall accuracy (57.5%). While post-processing is relatively straightforward to implement—since it does not require retraining the model and can be applied as a “bolt-on” adjustment—its severe impact on accuracy and potentially on other metrics (like precision or false positive rate) raises concerns. Moreover, deploying different thresholds for different groups might raise legal or ethical questions in some contexts.\n",
    "\n",
    "In summary, each intervention carries its own set of trade-offs. The dataset-based approach is the most practical to deploy and does not require changing the model architecture, but its effectiveness depends on the underlying data distribution and may not always reduce unfairness. In-processing methods directly target model training but can cause substantial drops in overall performance if not tuned correctly. Post-processing techniques offer a quick fix for balancing metrics like TPR, yet they might undermine the model’s predictive power and lead to lower accuracy. Ultimately, the most appropriate intervention for our task will depend on the specific legal, operational, and business requirements—balancing the need for fairness with acceptable performance levels across all metrics. \n",
    "\n",
    "Based on our results, the baseline model already performs quite well from both an accuracy and fairness perspective—it achieves 85.3% accuracy with a TPR difference of only 2.7% between the older (protected) and younger (unprotected) groups. Although our dataset-based intervention was designed to rebalance the training data, it actually increased the TPR gap to 5.4% while achieving a similar overall accuracy (85.8%). The model-based intervention further widened the gap (18% difference) and significantly reduced accuracy, while the post-processing intervention nearly equalized TPRs (a 1.6% gap) but at the expense of a dramatic drop in accuracy to 57.5%.\n",
    "\n",
    "Given these trade-offs, the baseline model appears to be the most practical choice—it delivers high accuracy and a relatively minimal TPR difference, which is both legally defensible and operationally effective. In many legal and regulatory environments, a 2.7% disparity may be considered acceptable, especially when it comes with a strong overall performance. Therefore, in this scenario, we would choose not to deploy an additional fairness intervention because the baseline already strikes a good balance between accuracy and fairness.\n",
    "\n",
    "In our case, when fairness interventions such as dataset-based, in-processing, or post-processing adjustments are applied,they resulted in widening the TPR gap or significantly drop overall accuracy with the gap to be lowered, which is not desirable from an operational standpoint. In many real-world applications, especially in regulated financial contexts, a small disparity may be legally acceptable if overall performance remains high. Thus, we conclude that the baseline model naturally strikes a good balance between accuracy and fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea869f1-0284-47ee-8faa-be6d6fdd0aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
